#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬å››æ­¥ï¼šé›¶æ°´å°ç”Ÿæˆå’ŒéªŒè¯
ä½¿ç”¨è®­ç»ƒå¥½çš„GATæ¨¡å‹æå–é²æ£’ç‰¹å¾ï¼Œç”Ÿæˆé›¶æ°´å°å¹¶è¿›è¡Œç‰ˆæƒéªŒè¯
ä¸ºæ¯ä¸ªåŸå§‹çŸ¢é‡åœ°å›¾ç”Ÿæˆå¯¹åº”çš„é›¶æ°´å°
"""

import os
import sys
import pickle
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm

# âœ… å¼ºåˆ¶UTF-8è¾“å‡ºç¼–ç ï¼ˆè§£å†³PowerShellæ˜¾ç¤ºé—®é¢˜ï¼‰
if sys.platform == 'win32':
    try:
        # è®¾ç½®æ ‡å‡†è¾“å‡ºä¸ºUTF-8
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        # Python 3.6åŠä»¥ä¸‹ç‰ˆæœ¬
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# âœ… ç¦ç”¨è¾“å‡ºç¼“å†²ï¼Œç¡®ä¿å®æ—¶æ˜¾ç¤º
os.environ['PYTHONUNBUFFERED'] = '1'

# è®¾ç½®ä¸­æ–‡å­—ä½“ - é€‚é…Windowsç¯å¢ƒ
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'Heiti SC', 'Songti SC']
    plt.rcParams['axes.unicode_minus'] = False
except:
    # å¦‚æœä¸­æ–‡å­—ä½“ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
    plt.rcParams['font.family'] = 'DejaVu Sans'

class WatermarkGenerator:
    """é›¶æ°´å°ç”Ÿæˆå™¨"""
    
    def __init__(self, model_path=None):
        # æ¨¡å‹è·¯å¾„æ”¹ä¸ºVGAT/modelsä¸‹ï¼Œä½¿ç”¨IMPROVEDç‰ˆæœ¬çš„æœ€ä½³æ¨¡å‹
        if model_path is None:
            model_path = os.path.join(os.path.dirname(__file__), '..', 'VGAT', 'models', 'gat_model_IMPROVED_best.pth')
        self.model_path = os.path.normpath(model_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.model = None
        self.load_model()
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            print("åŠ è½½è®­ç»ƒå¥½çš„æ”¹è¿›ç‰ˆGATæ¨¡å‹...")
            if os.path.exists(self.model_path):
                # å¯¼å…¥æ¨¡å‹ç±»ï¼ˆä½¿ç”¨importlibå› ä¸ºæ–‡ä»¶ååŒ…å«è¿å­—ç¬¦ï¼‰
                import sys
                import importlib.util
                
                base_dir = os.path.normpath(os.path.join(os.path.dirname(__file__), '..'))
                vgat_improved_path = os.path.join(base_dir, 'VGAT', 'VGAT-IMPROVED.py')
                
                # åŠ¨æ€åŠ è½½æ¨¡å—
                spec = importlib.util.spec_from_file_location("vgat_improved", vgat_improved_path)
                vgat_module = importlib.util.module_from_spec(spec)
                sys.modules['vgat_improved'] = vgat_module
                spec.loader.exec_module(vgat_module)
                
                ImprovedGATModel = vgat_module.ImprovedGATModel
                
                # ä½¿ç”¨IMPROVEDç‰ˆæœ¬çš„æ¨¡å‹å‚æ•°ï¼šinput_dim=20, hidden_dim=256, num_heads=8
                self.model = ImprovedGATModel(input_dim=20, hidden_dim=256, output_dim=1024, num_heads=8, dropout=0.3)
                
                # åŠ è½½æƒé‡
                checkpoint = torch.load(self.model_path, map_location=self.device)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.model.to(self.device)
                self.model.eval()
                
                print("æ”¹è¿›ç‰ˆGATæ¨¡å‹åŠ è½½å®Œæˆ")
                print(f"  è¾“å…¥ç»´åº¦: 20 (20ç»´å‡ ä½•ä¸å˜ç‰¹å¾)")
                print(f"  éšè—ç»´åº¦: 256")
                print(f"  è¾“å‡ºç»´åº¦: 1024")
                print(f"  æ³¨æ„åŠ›å¤´æ•°: 8")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {e}")
            import traceback
            print(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            raise
    
    def extract_robust_features(self, graph_data):
        """æå–é²æ£’ç‰¹å¾ï¼ˆå¤§å›¾ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼‰"""
        if not hasattr(graph_data, 'x') or not hasattr(graph_data, 'edge_index'):
            raise ValueError("è¾“å…¥å›¾æ•°æ®æ— æ•ˆï¼Œç¼ºå°‘å¿…è¦å±æ€§ 'x' æˆ– 'edge_index'")

        if self.model is None:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•æå–é²æ£’ç‰¹å¾")

        # ä½¿ç”¨è®­ç»ƒå¥½çš„GATæ¨¡å‹æå–ç‰¹å¾
        with torch.no_grad():
            features = self.model(graph_data.x.to(self.device), graph_data.edge_index.to(self.device))
            features = features.cpu().numpy()

        # ç¡®ä¿ç‰¹å¾æ˜¯ä¸€ç»´å‘é‡
        if features.ndim > 1:
            features = features.flatten()
        
        # æ–°æ¨¡å‹åº”è¯¥ç›´æ¥è¾“å‡º1024ç»´ç‰¹å¾ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ç¡®ä¿ç»´åº¦æ­£ç¡®
        if len(features) != 1024:
            print(f"è­¦å‘Šï¼šæ¨¡å‹è¾“å‡ºç‰¹å¾ç»´åº¦ä¸º{len(features)}ï¼ŒæœŸæœ›1024ç»´")
            # å¦‚æœç»´åº¦ä¸å¯¹ï¼Œè¿›è¡Œé€‚å½“è°ƒæ•´
            if len(features) < 1024:
                # ä½¿ç”¨é‡å¤å¡«å……åˆ°1024ç»´
                repeat_times = (1024 + len(features) - 1) // len(features)  # å‘ä¸Šå–æ•´
                features = np.tile(features, repeat_times)
            # å–å‰1024ç»´
            features = features[:1024]
        
        return features
    
    def load_copyright_image(self, image_path=None):
        """åŠ è½½ç‰ˆæƒå›¾åƒ"""
        try:
            if image_path is None:
                image_path = os.path.join(os.path.dirname(__file__), 'Cat32.png')
            image_path = os.path.normpath(image_path)
            image = Image.open(image_path)
            # è½¬æ¢ä¸ºäºŒå€¼å›¾åƒ
            image = image.convert('L')  # è½¬ä¸ºç°åº¦å›¾
            image = image.resize((32, 32))  # è°ƒæ•´å¤§å°ä¸º32x32
            # äºŒå€¼åŒ–
            threshold = 128
            image = image.point(lambda x: 0 if x < threshold else 255, '1')
            return np.array(image)
        except Exception as e:
            print(f"åŠ è½½ç‰ˆæƒå›¾åƒå¤±è´¥: {e}")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
            return np.random.randint(0, 2, (32, 32))
    
    def generate_zero_watermark(self, graph_data, copyright_image):
        """ç”Ÿæˆé›¶æ°´å°"""
        print("ç”Ÿæˆé›¶æ°´å°...")
        
        # æå–é²æ£’ç‰¹å¾
        robust_features = self.extract_robust_features(graph_data)
        
        # å°†ç‰¹å¾è½¬æ¢ä¸ºä¸ç‰ˆæƒå›¾åƒç›¸åŒå¤§å°çš„çŸ©é˜µ
        # ä½¿ç”¨ä¸­ä½æ•°é˜ˆå€¼ä»¥æå‡åŒºåˆ†åº¦ç¨³å®šæ€§
        feature_matrix = self.features_to_matrix(robust_features, copyright_image.shape, use_median_threshold=True)
        
        # ç”Ÿæˆé›¶æ°´å°ï¼ˆç‰¹å¾çŸ©é˜µä¸ç‰ˆæƒå›¾åƒçš„å¼‚æˆ–æ“ä½œï¼‰
        zero_watermark = np.logical_xor(feature_matrix, copyright_image).astype(np.uint8)
        
        return zero_watermark, robust_features
    
    def features_to_matrix(self, features, target_shape, use_median_threshold=False):
        """å°†ç‰¹å¾å‘é‡è½¬æ¢ä¸ºçŸ©é˜µ"""
        # å°†ç‰¹å¾å‘é‡é‡å¡‘ä¸ºç›®æ ‡å½¢çŠ¶
        total_elements = target_shape[0] * target_shape[1]
        
        # å¦‚æœç‰¹å¾æ•°é‡ä¸è¶³ï¼Œé‡å¤å¡«å……
        if len(features) < total_elements:
            features = np.tile(features, (total_elements // len(features) + 1,))
        
        # å–å‰total_elementsä¸ªå…ƒç´ 
        features = features[:total_elements]
        
        # é‡å¡‘ä¸ºç›®æ ‡å½¢çŠ¶
        matrix = features.reshape(target_shape)
        
        # äºŒå€¼åŒ–
        threshold = np.median(matrix) if use_median_threshold else np.mean(matrix)
        matrix = (matrix > threshold).astype(np.uint8)
        
        return matrix
    
    def verify_copyright(self, graph_data, zero_watermark, original_copyright):
        """éªŒè¯ç‰ˆæƒ"""
        print("éªŒè¯ç‰ˆæƒ...")
        
        # æå–é²æ£’ç‰¹å¾
        robust_features = self.extract_robust_features(graph_data)
        
        # å°†ç‰¹å¾è½¬æ¢ä¸ºçŸ©é˜µï¼ˆä¸ç”Ÿæˆé˜¶æ®µä¿æŒç›¸åŒçš„äºŒå€¼åŒ–ç­–ç•¥ï¼‰
        feature_matrix = self.features_to_matrix(robust_features, original_copyright.shape, use_median_threshold=True)
        
        # ä»é›¶æ°´å°ä¸­æå–ç‰ˆæƒå›¾åƒ
        extracted_copyright = np.logical_xor(zero_watermark, feature_matrix).astype(np.uint8)
        
        # è®¡ç®—NCå€¼ï¼ˆå½’ä¸€åŒ–ç›¸å…³ç³»æ•°ï¼‰
        nc_value = self.calculate_nc(original_copyright, extracted_copyright)
        
        return extracted_copyright, nc_value
    
    def calculate_nc(self, original, extracted):
        """è®¡ç®—å½’ä¸€åŒ–ç›¸å…³ç³»æ•°ï¼ˆNCå€¼ï¼‰"""
        # å°†å›¾åƒè½¬æ¢ä¸ºå‘é‡
        original_vec = original.flatten().astype(float)
        extracted_vec = extracted.flatten().astype(float)
        
        # è®¡ç®—å½’ä¸€åŒ–ç›¸å…³ç³»æ•°
        # NC = (AÂ·B) / (||A||Â·||B||)
        # å…¶ä¸­ AÂ·B æ˜¯ç‚¹ç§¯ï¼Œ||A|| å’Œ ||B|| æ˜¯å‘é‡çš„æ¨¡é•¿
        dot_product = np.sum(original_vec * extracted_vec)
        norm_original = np.sqrt(np.sum(original_vec ** 2))
        norm_extracted = np.sqrt(np.sum(extracted_vec ** 2))
        
        if norm_original == 0 or norm_extracted == 0:
            return 0.0
        
        nc = dot_product / (norm_original * norm_extracted)
        
        return nc
    
    def save_watermark(self, zero_watermark, filename, watermark_dir=None):
        """ä¿å­˜é›¶æ°´å°"""
        if watermark_dir is None:
            watermark_dir = os.path.join(os.path.dirname(__file__), 'ZeroWatermark', 'TrainingSet')
        watermark_dir = os.path.normpath(watermark_dir)
        if not os.path.exists(watermark_dir):
            os.makedirs(watermark_dir)
        
        # ä¿å­˜é›¶æ°´å°ä¸ºnumpyæ•°ç»„
        watermark_path = os.path.join(watermark_dir, f"{filename}_watermark.npy")
        np.save(watermark_path, zero_watermark)
        
        # ä¿å­˜é›¶æ°´å°å›¾åƒ
        image_path = os.path.join(watermark_dir, f"{filename}_watermark.png")
        watermark_image = Image.fromarray((zero_watermark * 255).astype(np.uint8))
        watermark_image.save(image_path)
        
        print(f"é›¶æ°´å°å·²ä¿å­˜: {watermark_path}")
        return watermark_path
    
    def save_results(self, zero_watermark, extracted_copyright, nc_value, filename, results_dir=None):
        """ä¿å­˜ç»“æœ"""
        if results_dir is None:
            results_dir = os.path.join(os.path.dirname(__file__), 'ZeroWatermark', 'TrainingSet')
        results_dir = os.path.normpath(results_dir)
        if not os.path.exists(results_dir):
            os.makedirs(results_dir)
        
        # ä¿å­˜é›¶æ°´å°
        plt.figure(figsize=(10, 5))
        
        plt.subplot(1, 3, 1)
        plt.imshow(zero_watermark, cmap='gray')
        plt.title('Zero Watermark')
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.imshow(extracted_copyright, cmap='gray')
        plt.title('Extracted Copyright')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.text(0.5, 0.5, f'NC Value: {nc_value:.4f}', 
                horizontalalignment='center', verticalalignment='center',
                transform=plt.gca().transAxes, fontsize=12)
        plt.title('Copyright Verification Result')
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, f'{filename}_watermark_results.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜æå–çš„ç‰ˆæƒå›¾åƒ
        extracted_image = Image.fromarray(extracted_copyright * 255)
        extracted_image.save(os.path.join(results_dir, f'{filename}_Cat32_Extract.png'))
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
        print(f"NCå€¼: {nc_value:.4f}")

class GraphDataLoader:
    """å›¾æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, graph_dir=None):
        if graph_dir is None:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿æ­£ç¡®æ‰¾åˆ°å›¾æ•°æ®ç›®å½•
            base_dir = os.path.normpath(os.path.join(os.path.dirname(__file__), '..'))
            graph_dir = os.path.join(base_dir, 'convertToGraph', 'Graph', 'TrainingSet')
        self.graph_dir = os.path.normpath(graph_dir)
        print(f"å›¾æ•°æ®åŠ è½½è·¯å¾„: {self.graph_dir}")
    
    def load_all_original_graphs(self):
        """åŠ è½½æ‰€æœ‰åŸå§‹å›¾æ•°æ®"""
        original_dir = os.path.join(self.graph_dir, 'Original')
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(original_dir):
            print(f"ç›®å½•ä¸å­˜åœ¨: {original_dir}")
            return [], []
        
        graphs = []
        filenames = []
        
        # åŠ è½½æ‰€æœ‰åŸå§‹å›¾
        for filename in os.listdir(original_dir):
            if filename.endswith('_graph.pkl'):
                try:
                    with open(os.path.join(original_dir, filename), 'rb') as f:
                        graph_data = pickle.load(f)
                        graphs.append(graph_data)
                        # æå–æ–‡ä»¶åï¼ˆå»æ‰_graph.pklåç¼€ï¼‰
                        base_name = filename.replace('_graph.pkl', '')
                        filenames.append(base_name)
                        print(f"æˆåŠŸåŠ è½½å›¾æ•°æ®: {filename}")
                except Exception as e:
                    print(f"åŠ è½½å›¾æ•°æ®å¤±è´¥ {filename}: {e}")
                    continue
        
        print(f"æ€»å…±åŠ è½½äº† {len(graphs)} ä¸ªå›¾æ•°æ®")
        return graphs, filenames

def main():
    """ä¸»å‡½æ•°"""
    # âœ… ç«‹å³è¾“å‡ºæµ‹è¯•ï¼Œç¡®ä¿ç»ˆç«¯å¯è§
    print("å¯åŠ¨é›¶æ°´å°ç”Ÿæˆè„šæœ¬...", flush=True)
    sys.stdout.flush()
    
    print("="*70)
    print("ç¬¬å››æ­¥ï¼šé›¶æ°´å°ç”Ÿæˆå’ŒéªŒè¯ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
    print("="*70)
    print("ä½¿ç”¨æ”¹è¿›çš„GATæ¨¡å‹ï¼ˆ20ç»´ç‰¹å¾ + ImprovedGATModelï¼‰")
    print("æ¨¡å‹é…ç½®ï¼šinput_dim=20, hidden_dim=256, num_heads=8")
    print("="*70)
    print()
    
    # æ¸…ç†è¾“å‡ºç›®å½•ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œå¯å®Œç¾æ›¿æ¢
    output_root = os.path.normpath(os.path.join(os.path.dirname(__file__), 'ZeroWatermark', 'TrainingSet'))
    if os.path.exists(output_root):
        print(f"æ¸…ç†æ—§çš„è¾“å‡ºç›®å½•: {output_root}")
        import shutil
        try:
            shutil.rmtree(output_root)
            print("[OK] æ—§æ•°æ®å·²æ¸…ç†")
        except Exception as e:
            print(f"[WARNING] æ¸…ç†ç›®å½•æ—¶å‡ºé”™: {e}")
            print("å°è¯•ç»§ç»­...")
    os.makedirs(output_root, exist_ok=True)
    print()
    
    # åŠ è½½æ‰€æœ‰åŸå§‹å›¾æ•°æ®
    data_loader = GraphDataLoader()
    original_graphs, filenames = data_loader.load_all_original_graphs()
    
    if not original_graphs:
        print("æ²¡æœ‰æ‰¾åˆ°å›¾æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œç¬¬äºŒæ­¥")
        return
    
    # åˆ›å»ºæ°´å°ç”Ÿæˆå™¨
    watermark_generator = WatermarkGenerator()
    
    # åŠ è½½ç‰ˆæƒå›¾åƒ
    copyright_image = watermark_generator.load_copyright_image()
    print(f"ç‰ˆæƒå›¾åƒå¤§å°: {copyright_image.shape}")
    
    # ä¸ºæ¯ä¸ªåŸå§‹å›¾ç”Ÿæˆé›¶æ°´å°
    all_nc_values = []
    
    skipped_graphs = []
    MAX_NODES = 30000  # èŠ‚ç‚¹æ•°é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™è·³è¿‡ï¼ˆé¿å…CUDA OOMå’Œç³»ç»Ÿå†…å­˜æº¢å‡ºï¼‰
    
    for i, (graph_data, filename) in enumerate(zip(original_graphs, filenames)):
        print(f"\nå¤„ç†ç¬¬ {i+1}/{len(original_graphs)} ä¸ªå›¾: {filename}")
        num_nodes = graph_data.x.size(0)
        num_edges = graph_data.edge_index.size(1)
        print(f"  èŠ‚ç‚¹æ•°: {num_nodes}, è¾¹æ•°: {num_edges}")
        
        # ğŸ›¡ï¸ é¢„æ£€æŸ¥ï¼šè¶…å¤§å›¾ç›´æ¥è·³è¿‡
        if num_nodes > MAX_NODES:
            print(f"âš ï¸ èŠ‚ç‚¹æ•°è¶…è¿‡é˜ˆå€¼ ({num_nodes} > {MAX_NODES})ï¼Œè·³è¿‡æ­¤å›¾é¿å…æ˜¾å­˜/å†…å­˜æº¢å‡º")
            skipped_graphs.append(f"{filename} (èŠ‚ç‚¹æ•°: {num_nodes})")
            continue
        
        try:
            # ç”Ÿæˆé›¶æ°´å°
            zero_watermark, robust_features = watermark_generator.generate_zero_watermark(
                graph_data, copyright_image
            )
            print(f"é›¶æ°´å°ç”Ÿæˆå®Œæˆ: {filename}")
            
            # éªŒè¯ç‰ˆæƒ
            extracted_copyright, nc_value = watermark_generator.verify_copyright(
                graph_data, zero_watermark, copyright_image
            )
            print(f"ç‰ˆæƒéªŒè¯å®Œæˆ: {filename}, NCå€¼: {nc_value:.4f}")
            
            # ä¿å­˜é›¶æ°´å°
            watermark_generator.save_watermark(zero_watermark, filename)
            
            # ä¿å­˜éªŒè¯ç»“æœ
            watermark_generator.save_results(zero_watermark, extracted_copyright, nc_value, filename)
            
            all_nc_values.append(nc_value)
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {filename}")
            print(f"   é”™è¯¯: {str(e)}")
            skipped_graphs.append(filename)
            continue
        
        finally:
            # âœ… æ¸…ç†CUDAç¼“å­˜ï¼Œé˜²æ­¢æ˜¾å­˜æº¢å‡º
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                import gc
                gc.collect()
    
    # è¾“å‡ºæ€»ä½“ç»“æœ
    print(f"\n{'='*70}")
    print(f"é›¶æ°´å°ç”Ÿæˆå’ŒéªŒè¯æ€»ä½“ç»“æœ")
    print(f"{'='*70}")
    print(f"æ€»å›¾æ•°é‡: {len(original_graphs)}")
    print(f"æˆåŠŸå¤„ç†: {len(all_nc_values)}")
    if skipped_graphs:
        print(f"è·³è¿‡çš„å›¾: {len(skipped_graphs)}")
        for sg in skipped_graphs:
            print(f"  - {sg}")
    print(f"å¹³å‡NCå€¼: {np.mean(all_nc_values):.4f}")
    print(f"æœ€é«˜NCå€¼: {np.max(all_nc_values):.4f}")
    print(f"æœ€ä½NCå€¼: {np.min(all_nc_values):.4f}")
    
    # æŒ‰ä¸åŒé˜ˆå€¼ç»Ÿè®¡æˆåŠŸç‡
    success_count_0_7 = sum(1 for nc in all_nc_values if nc > 0.7)
    success_count_0_8 = sum(1 for nc in all_nc_values if nc > 0.8)
    success_count_0_9 = sum(1 for nc in all_nc_values if nc > 0.9)
    
    print(f"\nç‰ˆæƒéªŒè¯æˆåŠŸç‡ç»Ÿè®¡:")
    print(f"  NC > 0.7: {success_count_0_7}/{len(original_graphs)} ({success_count_0_7/len(original_graphs)*100:.1f}%)")
    print(f"  NC > 0.8: {success_count_0_8}/{len(original_graphs)} ({success_count_0_8/len(original_graphs)*100:.1f}%)")
    print(f"  NC > 0.9: {success_count_0_9}/{len(original_graphs)} ({success_count_0_9/len(original_graphs)*100:.1f}%)")
    
    print(f"\nè¾“å‡ºç›®å½•: {output_root}")
    print(f"{'='*70}")
    print("[OK] æ‰€æœ‰é›¶æ°´å°ç”Ÿæˆå’ŒéªŒè¯å®Œæˆï¼")
    print(f"{'='*70}")

if __name__ == "__main__":
    main() 